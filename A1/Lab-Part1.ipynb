{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Word embedding and semantic change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.spatial.distance\n",
    "import scipy.stats\n",
    "import pickle\n",
    "import nltk\n",
    "from gensim.models import KeyedVectors\n",
    "import tqdm\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg65 = pd.read_csv('rg65.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cord</td>\n",
       "      <td>smile</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rooster</td>\n",
       "      <td>voyage</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noon</td>\n",
       "      <td>string</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fruit</td>\n",
       "      <td>furnace</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>autograph</td>\n",
       "      <td>shore</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word1    word2  similarity\n",
       "0       cord    smile        0.02\n",
       "1    rooster   voyage        0.04\n",
       "2       noon   string        0.04\n",
       "3      fruit  furnace        0.05\n",
       "4  autograph    shore        0.06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg65.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_words = nltk.corpus.brown.words()\n",
    "fdist = nltk.FreqDist(w.lower() for w in brown_words)\n",
    "brown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize LSA vectors from exercise\n",
    "with open('lsa-exercise.pkl', 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  WORDS = pickle_data['WORDS']\n",
    "  M2 = pickle_data['M2']\n",
    "  \n",
    "# Mapping between word and integer\n",
    "word_to_int = {}\n",
    "int_to_word = {}\n",
    "for ix, w in enumerate(sorted(list(WORDS))):\n",
    "  word_to_int[w] = ix\n",
    "  int_to_word[ix] = w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: cosine distance between embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(row):\n",
    "  return 1 - scipy.spatial.distance.cosine(model[row['word1']], model[row['word2']])\n",
    "\n",
    "rg65['w2v_similarity'] = rg65.apply(get_cosine_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.7720616169177829\n"
     ]
    }
   ],
   "source": [
    "# Pearson correlation\n",
    "print('Pearson correlation:', scipy.stats.pearsonr(rg65.similarity, rg65.w2v_similarity)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: analogy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with word-test-{all,semantic,syntactic}.txt\n",
    "with open('word-test-all.txt') as f:\n",
    "  lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy_words = []\n",
    "for line in lines:\n",
    "  line = line.lower()\n",
    "  line_words = line.split()\n",
    "  if len(line_words) == 4:\n",
    "    w1, w2, w3, w4 = line_words\n",
    "    if w1 in WORDS and w2 in WORDS and w3 in WORDS and w4 in WORDS:\n",
    "      analogy_words.append((w1, w2, w3, w4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1599 / 2207\n"
     ]
    }
   ],
   "source": [
    "def w2v_get_nearest(v, exclude):\n",
    "  best_cosine_distance = 1000\n",
    "  best_word = None\n",
    "  for w in WORDS:\n",
    "    if w not in model.vocab:\n",
    "      continue\n",
    "    if w in exclude:\n",
    "      continue\n",
    "    d = scipy.spatial.distance.cosine(v, model[w])\n",
    "    if d < best_cosine_distance:\n",
    "      best_cosine_distance = d\n",
    "      best_word = w\n",
    "  return best_word\n",
    "\n",
    "def w2v_process_analogy(inp):\n",
    "  w1, w2, w3, w4 = inp\n",
    "  return w2v_get_nearest(model[w3] + model[w2] - model[w1], [w1, w2, w3])\n",
    "\n",
    "# multi-threading to speed it up\n",
    "with mp.Pool() as pool:\n",
    "  analogy_results = pool.map(w2v_process_analogy, analogy_words)\n",
    "  \n",
    "w2v_correct = 0\n",
    "for (w1, w2, w3, w4), w_guess in zip(analogy_words, analogy_results):\n",
    "  if w4 == w_guess:\n",
    "    w2v_correct += 1\n",
    "print('Correct:', w2v_correct, '/', len(analogy_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/h/bai/moar/bai-conda/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 225 / 2207\n"
     ]
    }
   ],
   "source": [
    "def lsa_get_nearest(v, exclude):\n",
    "  best_cosine_distance = 1000\n",
    "  best_word = None\n",
    "  for w in WORDS:\n",
    "    if w in exclude:\n",
    "      continue\n",
    "    d = scipy.spatial.distance.cosine(v, M2[word_to_int[w]])\n",
    "    if d > 0 and d < best_cosine_distance:\n",
    "      best_cosine_distance = d\n",
    "      best_word = w\n",
    "  return best_word\n",
    "\n",
    "def lsa_process_analogy(inp):\n",
    "  w1, w2, w3, w4 = inp\n",
    "  return lsa_get_nearest(M2[word_to_int[w3]] + M2[word_to_int[w2]] - M2[word_to_int[w1]], [w1, w2, w3])\n",
    "\n",
    "# multi-threading to speed it up\n",
    "with mp.Pool() as pool:\n",
    "  analogy_results = pool.map(lsa_process_analogy, analogy_words)\n",
    "  \n",
    "lsa_correct = 0\n",
    "for (w1, w2, w3, w4), w_guess in zip(analogy_words, analogy_results):\n",
    "  if w4 == w_guess:\n",
    "    lsa_correct += 1\n",
    "print('Correct:', lsa_correct, '/', len(analogy_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
