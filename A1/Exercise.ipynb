{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Meaning construction from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import sklearn.decomposition\n",
    "import math\n",
    "import pickle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg65 = pd.read_csv('rg65.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cord</td>\n",
       "      <td>smile</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rooster</td>\n",
       "      <td>voyage</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noon</td>\n",
       "      <td>string</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fruit</td>\n",
       "      <td>furnace</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>autograph</td>\n",
       "      <td>shore</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word1    word2  similarity\n",
       "0       cord    smile        0.02\n",
       "1    rooster   voyage        0.04\n",
       "2       noon   string        0.04\n",
       "3      fruit  furnace        0.05\n",
       "4  autograph    shore        0.06"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg65.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: construct W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_words = nltk.corpus.brown.words()\n",
    "fdist = nltk.FreqDist(w.lower() for w in brown_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W = most common 5000 in Brown corpus + Table 1 of RG65\n",
    "WORDS = set([t[0] for t in fdist.most_common(5000)])\n",
    "WORDS.update(set(rg65.word1))\n",
    "WORDS.update(set(rg65.word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping between word and integer\n",
    "word_to_int = {}\n",
    "int_to_word = {}\n",
    "for ix, w in enumerate(sorted(list(WORDS))):\n",
    "  word_to_int[w] = ix\n",
    "  int_to_word[ix] = w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How frequent are the RG65 words?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for w in set(rg65.word1.tolist() + rg65.word2.tolist()):\n",
    "  print(w, fdist[w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: construct word-context matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = scipy.sparse.lil_matrix((len(WORDS), len(WORDS)))\n",
    "for w1, w2 in nltk.bigrams(brown_words):\n",
    "  w1 = w1.lower()\n",
    "  w2 = w2.lower()\n",
    "  if w1 in WORDS and w2 in WORDS:\n",
    "    M1[word_to_int[w1], word_to_int[w2]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: apply PPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1P = scipy.sparse.lil_matrix((len(WORDS), len(WORDS)))\n",
    "M1sum = M1.sum()\n",
    "rs, cs = M1.nonzero()\n",
    "for r, c in zip(rs, cs):\n",
    "  Pw1 = fdist[int_to_word[r]] / len(brown_words)\n",
    "  Pw2 = fdist[int_to_word[c]] / len(brown_words)\n",
    "  PJoint = M1[r, c] / M1sum\n",
    "  M1P[r, c] = max(0, math.log(PJoint / (Pw1 * Pw2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDIM = 300\n",
    "svd = sklearn.decomposition.TruncatedSVD(n_components=NDIM, random_state=12345)\n",
    "M2 = svd.fit_transform(M1P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: calculate cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to specify which matrix to use\n",
    "MTX = M2\n",
    "\n",
    "def get_cosine_similarity(row):\n",
    "  w1_ix = word_to_int[row['word1']]\n",
    "  w2_ix = word_to_int[row['word2']]\n",
    "  \n",
    "  # Discard ones that occur in less than 3 bigrams\n",
    "  if M1[w1_ix].sum() <= 2 or M1[w2_ix].sum() <= 2:\n",
    "    return None\n",
    "  \n",
    "  if scipy.sparse.issparse(MTX):\n",
    "    return 1 - scipy.spatial.distance.cosine(MTX[w1_ix].todense(), MTX[w2_ix].todense())\n",
    "  else:\n",
    "    return 1 - scipy.spatial.distance.cosine(MTX[w1_ix], MTX[w2_ix])\n",
    "\n",
    "rg65['lsa_similarity'] = rg65.apply(get_cosine_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Pearson correlation\n",
    "\n",
    "Results:\n",
    "```\n",
    "M1: 0.21639005014068902\n",
    "M1P: 0.41548942500838\n",
    "M2_10: 0.1333050985847491\n",
    "M2_100: 0.329345887621373\n",
    "M2_300: 0.41080191606630956\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41080191606630956, 0.008460381079860498)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg_notnull = rg65.dropna()\n",
    "scipy.stats.pearsonr(rg_notnull.similarity, rg_notnull.lsa_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lsa-exercise.pkl', 'wb') as f:\n",
    "  pickle.dump({'WORDS': WORDS, 'M2': M2}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
